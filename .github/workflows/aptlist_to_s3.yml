name: Update Apartment List CSV to S3 (Headless)

on:
  schedule:
    - cron: "20 9 19 * *"   # Monthly on 19th at 09:20 UTC
  workflow_dispatch:
    inputs:
      option_name:
        description: 'Dropdown option to select'
        required: false
        default: 'Historic Rent Estimates (Jan 2017 - Present)'
        type: string

permissions:
  id-token: write
  contents: read

jobs:
  upload:
    runs-on: ubuntu-latest
    concurrency:
      group: aptlist-upload
      cancel-in-progress: false

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Assume AWS role (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::607709788146:role/RentSignalsGhOidcUploader
          aws-region: us-east-1

      - name: Setup Python + Playwright
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: |
          python -m pip install --upgrade pip
          pip install playwright==1.47.0 pandas
          python -m playwright install --with-deps chromium

      - name: Download AptList CSV (headless)
        run: |
          set -euo pipefail
          mkdir -p data
          python - <<'PY'
          import asyncio, re
          from pathlib import Path
          from playwright.async_api import async_playwright
          URL = "https://www.apartmentlist.com/research/category/data-rent-estimates"
          OUT = Path("data/apartmentlist_raw.csv")
          async def main():
            async with async_playwright() as p:
              b = await p.chromium.launch(headless=True)
              ctx = await b.new_context(accept_downloads=True,
                                        user_agent=("Mozilla/5.0 (X11; Linux x86_64) "
                                                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                                                    "Chrome/123 Safari/537.36"))
              page = await ctx.new_page()
              await page.goto(URL, wait_until="domcontentloaded", timeout=60000)
              # select the first option: Historic Rent Estimates (Jan 2017 - Present)
              try:
                combo = page.get_by_role("combobox").first
                await combo.click()
                opt = page.get_by_role("option", name=re.compile(r"Historic Rent Estimates", re.I))
                await opt.click()
              except Exception:
                pass
              btn = page.get_by_role("button", name=re.compile(r"^Download$", re.I))
              if await btn.count()==0:
                raise SystemExit("Download button not found")
              async with page.expect_download(timeout=45000) as dl_info:
                await btn.first.click()
              dl = await dl_info.value
              OUT.write_bytes(Path(await dl.path()).read_bytes())
              print("Downloaded:", dl.suggested_filename)
              await b.close()
          asyncio.run(main())
          PY
          head -n 2 data/apartmentlist_raw.csv

      - name: Normalize to long format
        run: |
          python - <<'PY'
          import re, pandas as pd
          src = "data/apartmentlist_raw.csv"
          dst = "data/apartmentlist_long.csv"
          df  = pd.read_csv(src)

          cols = [c.lower().strip() for c in df.columns]
          # Already long?
          if "month" in cols and "rent_index" in cols:
              rename = {
                'location name':'location_name','location':'location_name',
                'location_type':'location_type',
                'location fips code':'location_fips_code','location_fips_code':'location_fips_code',
                'population':'population','state':'state','county':'county','metro':'metro',
                'rent_index':'rent_index','month':'month'
              }
              df = df.rename(columns={c:rename.get(c.lower().strip(),c) for c in df.columns})
              keep = ['location_name','location_type','location_fips_code','population',
                      'state','county','metro','rent_index','month']
              for k in keep:
                  if k not in df.columns: df[k] = None
              df[keep].to_csv(dst, index=False)
          else:
              # Wide -> long: identify id cols + YYYY_MM or YYYY-MM( -DD ) columns
              dfn = df.rename(columns={c:c.lower().strip() for c in df.columns})
              id_candidates = ['location_name','location type','location_type',
                               'location fips code','location_fips_code',
                               'population','state','county','metro']
              id_cols = [c for c in dfn.columns if c in id_candidates]
              if not id_cols:
                  id_cols = [c for c in dfn.columns if c in ['location_name','state','county','metro']]
              date_cols = [c for c in dfn.columns if re.fullmatch(r'\d{4}[-_]\d{2}([-_]\d{2})?', c)]
              if not date_cols:
                  raise SystemExit("No date columns found to melt")

              long = dfn.melt(id_vars=id_cols, value_vars=date_cols,
                              var_name='month', value_name='rent_index')
              long['month'] = pd.to_datetime(long['month'].str.replace('_','-')).dt.date
              out = pd.DataFrame({
                'location_name': long.get('location_name'),
                'location_type': long.get('location_type'),
                'location_fips_code': long.get('location_fips_code'),
                'population': long.get('population'),
                'state': long.get('state'),
                'county': long.get('county'),
                'metro': long.get('metro'),
                'rent_index': long['rent_index'],
                'month': long['month'],
              })
              out.to_csv(dst, index=False)

          print("Wrote", dst)
          PY
          head -n 2 data/apartmentlist_long.csv

      - name: Upload to S3
        env:
          BUCKET: ${{ vars.RENT_SIGNALS_BUCKET }}
        run: |
          set -euo pipefail
          if [[ -z "${BUCKET:-}" ]]; then echo "Error: RENT_SIGNALS_BUCKET variable not set"; exit 1; fi
          TODAY=$(date -u +%F)
          echo "Uploading to S3 bucket: $BUCKET"
          echo "Date prefix: $TODAY"
          
          aws s3api put-object --bucket "$BUCKET" --key "aptlist/$TODAY/"
          aws s3 cp data/apartmentlist_long.csv "s3://$BUCKET/aptlist/$TODAY/apartmentlist_long.csv"
          
          echo "✅ Upload completed"

      - name: Verify S3 upload
        env:
          BUCKET: ${{ vars.RENT_SIGNALS_BUCKET }}
        run: |
          TODAY=$(date -u +%F)
          echo "Verifying upload to s3://$BUCKET/aptlist/$TODAY/"
          aws s3 ls "s3://$BUCKET/aptlist/$TODAY/"
          echo "✅ Upload verification completed"